{"id": "660fb729-de11-4918-a54f-a02b80fdbd69", "displayed_text": "Title: OrdinalCLIP: Learning Rank Prompts for Language-Guided Ordinal Regression\nAbstract: This paper presents a language-powered paradigm for ordinal regression. Existing methods usually treat each rank as a category and employ a set of weights to learn these concepts. These methods are easy to overfit and usually attain unsatisfactory performance as the learned concepts are mainly derived from the training set. Recent large pre-trained vision-language models like CLIP have shown impressive performance on various visual tasks. In this paper, we propose to learn the rank concepts from the rich semantic CLIP latent space. Specifically, we reformulate this task as an image-language matching problem with a contrastive objective, which regards labels as text and obtains a language prototype from a text encoder for each rank. While prompt engineering for CLIP is extremely time-consuming, we propose OrdinalCLIP, a differentiable prompting method for adapting CLIP for ordinal regression. OrdinalCLIP consists of learnable context tokens and learnable rank embeddings; The learnable rank embeddings are constructed by explicitly modeling numerical continuity, resulting in well-ordered, compact language prototypes in the CLIP space. Once learned, we can only save the language prototypes and discard the huge language model, resulting in zero additional computational overhead compared with the linear head counterpart. Experimental results show that our paradigm achieves competitive performance in general ordinal regression tasks, and gains improvements in few-shot and distribution shift settings for age estimation.", "label_annotations": {"Multi-aspect Summary": {"Context": "Existing ordinal regression methods often overfit and underperform by treating each rank as a separate category, deriving concepts mainly from training data.", "Key idea": "The paper proposes OrdinalCLIP, using CLIP's semantic latent space and differentiable prompting to learn rank concepts as language prototypes.\r\n", "Validation": "The study uses experimental results from general ordinal regression tasks, few-shot, and distribution shift settings for age estimation to validate the method.", "Outcome": " OrdinalCLIP achieves competitive performance in general ordinal regression tasks and improves results in few-shot and distribution shift settings.", "Future Impact": " The approach suggests efficient ordinal regression techniques, reducing computational overhead and encouraging further research on language-guided models."}}, "span_annotations": {}, "behavioral_data": {"time_string": "Time spent: 0d 0h 0m 4s "}}
{"id": "3477752b-3858-4954-80f0-565df69fbb55", "displayed_text": "Title: Sqrt(d) Dimension Dependence of Langevin Monte Carlo\nAbstract: This article considers the popular MCMC method of unadjusted Langevin Monte Carlo (LMC) and provides a non-asymptotic analysis of its sampling error in 2-Wasserstein distance. The proof is based on a refinement of mean-square analysis in Li et al. (2019), and this refined framework automates the analysis of a large class of sampling algorithms based on discretizations of contractive SDEs. Using this framework, we establish an O(sqrt(d)/sigma) mixing time bound for LMC, without warm start, under the common log-smooth and log-strongly-convex conditions, plus a growth condition on the 3rd-order derivative of the potential of target measures. This bound improves the best previously known O(d/sigma)  result and is optimal (in terms of order) in both dimension d and accuracy tolerance _ for target measures satisfying the aforementioned assumptions. Our theoretical analysis is further validated by numerical experiments.", "label_annotations": {"Multi-aspect Summary": {"Context": "This study addresses the sampling error analysis of Langevin Monte Carlo (LMC) in 2-Wasserstein distance, enhancing understanding of MCMC methods for contractive SDEs discretizations.", "Key idea": "The paper refines mean-square analysis to automate the analysis of sampling algorithms, establishing an optimal  O( d/\u03f5) mixing time bound for LMC under specific conditions, improving previous results.\r\n", "Validation": "The study's theoretical analysis is validated through numerical experiments, confirming the effectiveness of the proposed approach", "Outcome": "The paper achieves an optimal mixing time bound for LMC, improving understanding of MCMC methods' efficiency and accuracy in high-dimensional spaces.", "Future Impact": "This work may lead to advancements in MCMC methods, particularly in improving sampling efficiency and accuracy in high-dimensional spaces, encouraging further research in this area."}}, "span_annotations": {}, "behavioral_data": {"time_string": "Time spent: 0d 0h 1m 30s "}}
