{"id": "3477752b-3858-4954-80f0-565df69fbb55", "displayed_text": "Title: Sqrt(d) Dimension Dependence of Langevin Monte Carlo\nAbstract: This article considers the popular MCMC method of unadjusted Langevin Monte Carlo (LMC) and provides a non-asymptotic analysis of its sampling error in 2-Wasserstein distance. The proof is based on a refinement of mean-square analysis in Li et al. (2019), and this refined framework automates the analysis of a large class of sampling algorithms based on discretizations of contractive SDEs. Using this framework, we establish an Oe d/_ mixing time bound for LMC, without warm start, under the common log-smooth and log-strongly-convex conditions, plus a growth condition on the 3rd-order derivative of the potential of target measures. This bound improves the best previously known Oe ", "label_annotations": {"Multi-aspect Summary": {"Context": "Previous research has not sufficiently addressed the sampling error of unadjusted Langevin Monte Carlo (LMC) in 2-Wasserstein distance under certain conditions.", "Key idea": "This paper refines the mean-square analysis to provide a non-asymptotic analysis of LMC's sampling error, establishing a new mixing time bound.", "Validation": "The study uses a theoretical framework based on discretizations of contractive SDEs and analyzes sampling error under log-smooth, log-strongly-convex conditions.", "Outcome": "The new framework improves the best-known mixing time bound for LMC, providing more accurate predictions without the need for a warm start.", "Future Impact": "The refined analysis method may inspire further research into more efficient MCMC algorithms and broader applications in sampling and optimization problems."}}, "span_annotations": {}, "behavioral_data": {"time_string": "Time spent: 0d 0h 4m 18s "}}
{"id": "e6e3b00f-54a1-4d4b-a927-c669559491fd", "displayed_text": "Title: Geometry-aware Instance-reweighted Adversarial Training\nAbstract: In adversarial machine learning, there was a common belief that robustness and accuracy hurt each other. The belief was challenged by recent studies where we can maintain the robustness and improve the accuracy. However, the other direc- tion, we can keep the accuracy and improve the robustness, is conceptually and practically more interesting, since robust accuracy should be lower than standard accuracy for any model. In this paper, we show this direction is also promising. Firstly, we find even over-parameterized deep networks may still have insufficient model capacity, because adversarial training has an overwhelming smoothing ef- fect. Secondly, given limited model capacity, we argue adversarial data should have unequal importance: geometrically speaking, a natural data point closer to/farther from the class boundary is less/more robust, and the corresponding ad- versarial data point should be assigned with larger/smaller weight. Finally, to implement the idea, we propose geometry-aware instance-reweighted adversar- ial training, where the weights are based on how difficult it is to attack a natural data point. Experiments show that our proposal boosts the robustness of standard adversarial training; combining two directions, we improve both robustness and accuracy of standard adversarial training.", "label_annotations": {"Multi-aspect Summary": {"Context": "The belief that robustness and accuracy in adversarial machine learning are mutually exclusive motivates this study.", "Key idea": "The paper proposes geometry-aware instance-reweighted adversarial training, assigning weights to adversarial data based on attack difficulty.", "Validation": "The study uses experimental setups to demonstrate the effectiveness of geometry-aware instance-reweighted adversarial training.", "Outcome": "The proposed method improves both robustness and accuracy in standard adversarial training.", "Future Impact": "The approach suggests new avenues for enhancing model robustness without sacrificing accuracy, encouraging further research in adversarial training techniques."}}, "span_annotations": {}, "behavioral_data": {"time_string": "Time spent: 0d 0h 4m 8s "}}
