{"id": "4c81f948-f4b2-4130-92e5-623d942f0859", "displayed_text": "Title: DropCov: A Simple yet Effective Method for Improving Deep Architectures\nAbstract: Previous works show global covariance pooling (GCP) has great potential to improve deep architectures especially on visual recognition tasks, where post- normalization of GCP plays a very important role in final performance.  Although several post-normalization strategies have been studied, these methods pay more close attention to effect of normalization on covariance representations rather than the whole GCP networks, and their effectiveness requires further understanding.  Meanwhile, existing effective post-normalization strategies (e.g., matrix power normalization) usually suffer from high computational complexity (e.g., O(d3) for d-dimensional inputs).  To handle above issues, this work first analyzes the effect of post-normalization from the perspective of training GCP networks.  Particularly, we for the first time show that effective post-normalization can make a good trade-off between representation decorrelation and information preservation for GCP, which are crucial to alleviate over-fitting and increase representation ability of deep GCP networks, respectively.  Based on this finding, we can improve existing post- normalization methods with some small modifications, providing further support to our observation.  Furthermore, this finding encourages us to propose a novel pre-normalization method for GCP (namely DropCov), which develops an adaptive channel dropout on features right before GCP, aiming to reach trade-off between representation decorrelation and information preservation in a more efficient way.  Our DropCov only has a linear complexity of O(d), while being free for inference.  Extensive experiments on various benchmarks (i.e., ImageNet-1K, ImageNet-C, ImageNet-A, Stylized-ImageNet, and iNat2017) show our DropCov is superior to the counterparts in terms of efficiency and effectiveness, and provides a simple yet effective method to improve performance of deep architectures involving both deep convolutional neural networks (CNNs) and vision transformers (ViTs).", "label_annotations": {"Multi-aspect Summary": {"Context": "Existing global covariance pooling (GCP) methods improve deep architectures but suffer from high computational complexity and suboptimal post-normalization effectiveness.", "Key idea": " The paper proposes DropCov, a pre-normalization method using adaptive channel dropout to balance representation decorrelation and information preservation efficiently.", "Validation": "The study uses extensive experiments on benchmarks like ImageNet-1K, ImageNet-C, ImageNet-A, Stylized-ImageNet, and iNat2017 to validate DropCov's performance.", "Outcome": "DropCov outperforms existing methods in efficiency and effectiveness, providing a linear complexity solution for improving deep architectures.", "Future Impact": "This method could lead to more efficient deep learning models, inspiring further research on pre-normalization techniques and their applications."}}, "span_annotations": {}, "behavioral_data": {"time_string": "Time spent: 0d 0h 2m 14s "}}
{"id": "e6e3b00f-54a1-4d4b-a927-c669559491fd", "displayed_text": "Title: Geometry-aware Instance-reweighted Adversarial Training\nAbstract: In adversarial machine learning, there was a common belief that robustness and accuracy hurt each other. The belief was challenged by recent studies where we can maintain the robustness and improve the accuracy. However, the other direc- tion, we can keep the accuracy and improve the robustness, is conceptually and practically more interesting, since robust accuracy should be lower than standard accuracy for any model. In this paper, we show this direction is also promising. Firstly, we find even over-parameterized deep networks may still have insufficient model capacity, because adversarial training has an overwhelming smoothing ef- fect. Secondly, given limited model capacity, we argue adversarial data should have unequal importance: geometrically speaking, a natural data point closer to/farther from the class boundary is less/more robust, and the corresponding ad- versarial data point should be assigned with larger/smaller weight. Finally, to implement the idea, we propose geometry-aware instance-reweighted adversar- ial training, where the weights are based on how difficult it is to attack a natural data point. Experiments show that our proposal boosts the robustness of standard adversarial training; combining two directions, we improve both robustness and accuracy of standard adversarial training.", "label_annotations": {"Multi-aspect Summary": {"Context": "Traditional belief holds that robustness and accuracy in adversarial machine learning are mutually exclusive, motivating the exploration of improving robustness without sacrificing accuracy.", "Key idea": "The paper introduces geometry-aware instance-reweighted adversarial training, assigning weights based on the difficulty of attacking natural data points.", "Validation": "Experiments are conducted to show that the proposed method enhances the robustness of standard adversarial training while maintaining accuracy.", "Outcome": "The proposed method successfully improves both robustness and accuracy in adversarial training.", "Future Impact": "This approach may inspire new strategies in adversarial training, balancing robustness and accuracy, and encouraging further research in this direction.\r\n"}}, "span_annotations": {}, "behavioral_data": {"time_string": "Time spent: 0d 0h 0m 47s "}}
